{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d2c77bf-ca28-42c9-bdcd-0737bd3d90b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. What is Ridge Regression, and how does it differ from ordinary least squares regression?\n",
    "# Ans :Ridge regression is a model tuning method that is used to analyse any data that suffers from multicollinearity. This \n",
    "# method performs L2 regularization. When the issue of multicollinearity occurs, least-squares are unbiased, and variances are \n",
    "# large, this results in predicted values being far away from the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3b209db-44e9-4118-8c29-7b1686c73ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. What are the assumptions of Ridge Regression?\n",
    "# Ans The assumptions of ridge regression are the same as that of linear regression: linearity, constant variance, and independence. However, \n",
    "# as ridge regression does not provide confidence limits, the distribution of errors to be normal need not be assumed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abf54763-7511-4866-94f0-e7e85f7060df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. How do you select the value of the tuning parameter (lambda) in Ridge Regression?\n",
    "# Ans\n",
    "    # Ridge regression\n",
    "    # Selecting a good value for λ is critical. When λ=0, the penalty term has no effect, and ridge regression will produce the \n",
    "    # classical least square coefficients. However, as λ increases to infinite, the impact of the shrinkage penalty grows, and the \n",
    "    # ridge regression coefficients will get close zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bca929ce-5684-45d9-ae1a-5e078b163a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. Can Ridge Regression be used for feature selection? If yes, how?\n",
    "# Ans     \n",
    "#     Ridge regression is a type of regularized linear regression that introduces a penalty term on the size of the coefficients.\n",
    "#     This penalty term helps to prevent overfitting and improve the generalization performance of the model. However, ridge regression by itself\n",
    "#     does not perform feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28df8c7d-d696-4f85-a1b1-3c69a73a45ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5. How does the Ridge Regression model perform in the presence of multicollinearity?\n",
    "# Ans Ridge regression is a regularized linear regression method that is used to deal with the issue of multicollinearity in a dataset. \n",
    "# Multicollinearity refers to the situation where two or more predictor variables are highly correlated with each other, which can lead to \n",
    "# unstable and unreliable estimates of the regression coefficients.\n",
    "\n",
    "# In the presence of multicollinearity, the ordinary least squares (OLS) method of linear regression tends to give large coefficients to the\n",
    "# correlated variables, making the model overfit and potentially leading to erroneous predictions. Ridge regression addresses this issue by adding\n",
    "# a penalty term to the regression coefficients, which reduces their size and variance, and thus helps to stabilize the estimates.\n",
    "\n",
    "# Therefore, Ridge regression is generally considered to perform well in the presence of multicollinearity, as it can handle correlated predictor \n",
    "# variables by reducing the impact of each variable on the outcome variable. By constraining the size of the coefficients, Ridge regression helps\n",
    "# to prevent overfitting and improve the generalization performance of the model.\n",
    "\n",
    "# However, it is important to note that Ridge regression cannot completely eliminate the problem of multicollinearity, as it only reduces the \n",
    "# impact of correlated variables rather than removing them from the model. Therefore, it is still important to identify and address multicollinearity\n",
    "# in the data before applying Ridge regression or any other regression method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54caa326-4c0e-483e-a4b1-af8107c1776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ans 6 . Can Ridge Regression handle both categorical and continuous independent variables?\n",
    "# Ans6 Ridge regression can handle both categorical and continuous independent variables. However, before fitting the model, \n",
    "# categorical variables need to be encoded as numerical values, such as one-hot encoding.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a50366-8623-49a6-878f-57b5aee3afc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7. How do you interpret the coefficients of Ridge Regression?\n",
    "# Ans 7.The coefficients of Ridge Regression are interpreted in the same way as in linear regression. They represent the change in the \n",
    "# response variable for a one-unit increase in the predictor variable while holding all other predictors constant. In Ridge Regression, the\n",
    "# coefficients are also penalized to reduce overfitting. As a result, the coefficients are shrunk towards zero, which can be interpreted as \n",
    "# a trade-off between bias and variance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fa7e4d-db60-4fe4-8596-75f96f6e10ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8. Can Ridge Regression be used for time-series data analysis? If yes, how?\n",
    "# Ans 8 Ridge regression can be used for time-series data analysis, but it requires some modifications. \n",
    "# In time-series analysis, autocorrelation is often present, which violates the assumption of independent observations required by\n",
    "# Ridge Regression. To address this issue, one can use techniques such as autoregressive integrated moving average (ARIMA) or exponential \n",
    "# smoothing methods before applying Ridge Regression. Another approach is to use a time-series version of Ridge Regression, such as Bayesian\n",
    "# Ridge Regression or Time-varying Ridge Regression, which incorporate time dependencies into the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
